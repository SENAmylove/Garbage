import copy
import os
import numpy as np
import torch
import torch.optim as optim
import torch.nn.functional as F
from gripmodel import GRIPModel,GRIPModel_with_replaced_graph_param, GRIPModel_with_replaced_graph_param_return_graph
from ngsim_feeder import Feeder
from datetime import datetime
import random
from ngsim_utils import my_print, my_save_model, data_loader, display_result, save_model, data_loader_with_Adj, data_loader_with_drop, data_loader_with_drop_se
from explainer import Explainer
import pandas as pd
import plotly.express as px
from scipy.spatial.distance import cosine
from scipy.special import softmax
from loguru import logger


def seed_torch(seed=0):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True
seed_torch()

# ---
max_x = 1.
max_y = 1.
history_frames = 6  # 3 second * 2 frame/second
future_frames = 6  # 3 second * 2 frame/second

batch_size_train = 64
batch_size_val = 32
batch_size_test = 1
total_epoch = 50
base_lr = 0.01
lr_decay_epoch = 5
dev = 'cuda:0'
work_dir = './trained_models'
log_file = os.path.join(work_dir, 'log.txt')
test_result_file = 'prediction_result.txt'
# ---

if not os.path.exists(work_dir):
    os.makedirs(work_dir)


def preprocess_data(pra_data, pra_rescale_xy):
    # pra_data: (N, C, T, V)
    # N -> Batch Size
    # C -> Feature Size
    # T -> Temporal
    # V -> maximum size of targets

    # C = 19: [Vehicle_ID,Frame_ID,Total_Frames,Global_Time,Local_X,Local_Y,Global_X,Global_Y,v_Length,v_Width,
    # v_Class,v_Vel,v_Acc,Lane_ID,Preceding,Following,Space_Headway,Time_Headway] + [mask]

    # 取出 feature
    # Local_X, Local_Y, v_Length, v_Width ,Space_Headway + [mask]
    feature_id = [4, 5, 8, 9, 16, 18]
    ori_data = pra_data[:, feature_id].detach()
    # 复制一份
    data = ori_data.detach().clone()
    # 计算速度 \delta X 和 \delta Y
    new_mask = (data[:, :2, 1:] != 0) * (data[:, :2, :-1] != 0)
    data[:, :2, 1:] = (data[:, :2, 1:] - data[:, :2, :-1]).float() * new_mask.float()
    data[:, :2, 0] = 0

    # 1 - motorcycle, 2 - auto, 3 - truck
    object_type = pra_data[:, 10:11]

    data = data.float().to(dev)
    ori_data = ori_data.float().to(dev)
    object_type = object_type.to(dev)  # type
    data[:, :2] = data[:, :2] / pra_rescale_xy

    return data, ori_data, object_type

def compute_RMSE(pra_pred, pra_GT, pra_mask, pra_error_order=2):
    pred = pra_pred * pra_mask  # (N, C, T, V)=(N, 2, 6, 120)
    GT = pra_GT * pra_mask  # (N, C, T, V)=(N, 2, 6, 120)

    x2y2 = torch.sum(torch.abs(pred - GT) ** pra_error_order, dim=1)  # x^2+y^2, (N, C, T, V)->(N, T, V)=(N, 6, 120)
    overall_sum_time = x2y2.sum(dim=-1)  # (N, T, V) -> (N, T)=(N, 6)
    overall_mask = pra_mask.sum(dim=1).sum(dim=-1)  # (N, C, T, V) -> (N, T)=(N, 6)
    overall_num = overall_mask

    return overall_sum_time, overall_num, x2y2


def train_model(pra_model, pra_data_loader, pra_optimizer, pra_epoch_log):
    # writer
    # writer = SummaryWriter()
    # pra_model.to(dev)
    pra_model.train()
    rescale_xy = torch.ones((1, 2, 1, 1)).to(dev)
    rescale_xy[:, 0] = max_x
    rescale_xy[:, 1] = max_y

    # train model using training data
    for iteration, (ori_data, A, _) in enumerate(pra_data_loader):
        # print(iteration, ori_data.shape, A.shape)
        # ori_data: (N, C, T, V)
        # C = [Vehicle_ID,Frame_ID,Total_Frames,Global_Time,Local_X,Local_Y,Global_X,Global_Y,v_Length,v_Width,v_Class,
        # v_Vel,v_Acc,Lane_ID,Preceding,Following,Space_Headway,Time_Headway] + [mask]
        data, no_norm_loc_data, object_type = preprocess_data(ori_data, rescale_xy)

        loss_per_iteration = []
        for now_history_frames in range(1, data.shape[-2]):
            input_data = data[:, :, :now_history_frames, :]  # (N, C, T, V) = (N, 11, 6, 120)
            output_loc_GT = data[:, :2, now_history_frames:, :]  # (N, C, T, V)=(N, 2, 6, 120)
            output_mask = data[:, -1:, now_history_frames:, :]  # (N, C, T, V)=(N, 1, 6, 120)

            A = A.float().to(dev)

            predicted = pra_model(pra_x=input_data, pra_A=A, pra_pred_length=output_loc_GT.shape[-2],
                                  pra_teacher_forcing_ratio=0,
                                  pra_teacher_location=output_loc_GT)  # (N, C, T, V)=(N, 2, 6, 120)

            ########################################################
            # Compute loss for training
            ########################################################
            # We use abs to compute loss to backward update weights
            # (N, T), (N, T)
            overall_sum_time, overall_num, _ = compute_RMSE(predicted, output_loc_GT, output_mask, pra_error_order=1)
            # overall_loss
            total_loss = torch.sum(overall_sum_time) / torch.max(torch.sum(overall_num),torch.ones(1, ).to(dev))  # (1,)

            now_lr = [param_group['lr'] for param_group in pra_optimizer.param_groups][0]
            my_print(
                '|{}|{:>20}|\tIteration:{:>5}|\tLoss:{:.8f}|lr: {}|'.format(datetime.now(), pra_epoch_log, iteration,
                                                                            total_loss.data.item(), now_lr), log_file)
            loss_per_iteration.append(total_loss.data.item())
            pra_optimizer.zero_grad()
            total_loss.backward()
            pra_optimizer.step()

        # writer.add_scalar(f'{pra_epoch_log}_Iteration/loss', np.mean(loss_per_iteration), iteration)


def train_model_weight_returned_graphs(pra_model, pra_data_loader, pra_optimizer, pra_epoch_log):
    # writer
    # writer = SummaryWriter()
    # pra_model.to(dev)
    pra_model.train()
    rescale_xy = torch.ones((1, 2, 1, 1)).to(dev)
    rescale_xy[:, 0] = max_x
    rescale_xy[:, 1] = max_y

    # train model using training data
    for iteration, (ori_data, A, _) in enumerate(pra_data_loader):
        # print(iteration, ori_data.shape, A.shape)
        # ori_data: (N, C, T, V)
        # C = [Vehicle_ID,Frame_ID,Total_Frames,Global_Time,Local_X,Local_Y,Global_X,Global_Y,v_Length,v_Width,v_Class,
        # v_Vel,v_Acc,Lane_ID,Preceding,Following,Space_Headway,Time_Headway] + [mask]
        data, no_norm_loc_data, object_type = preprocess_data(ori_data, rescale_xy)

        loss_per_iteration = []
        for now_history_frames in range(1, data.shape[-2]):
            input_data = data[:, :, :now_history_frames, :]  # (N, C, T, V) = (N, 11, 6, 120)
            output_loc_GT = data[:, :2, now_history_frames:, :]  # (N, C, T, V)=(N, 2, 6, 120)
            output_mask = data[:, -1:, now_history_frames:, :]  # (N, C, T, V)=(N, 1, 6, 120)

            A = A.float().to(dev)

            predicted, fresh_graph_list  = pra_model(pra_x=input_data, pra_A=A, pra_pred_length=output_loc_GT.shape[-2],
                                  pra_teacher_forcing_ratio=0,
                                  pra_teacher_location=output_loc_GT)  # (N, C, T, V)=(N, 2, 6, 120)

            ########################################################
            # Compute loss for training
            ########################################################
            # We use abs to compute loss to backward update weights
            # (N, T), (N, T)
            overall_sum_time, overall_num, _ = compute_RMSE(predicted, output_loc_GT, output_mask, pra_error_order=1)
            # overall_loss
            total_loss = torch.sum(overall_sum_time) / torch.max(torch.sum(overall_num),torch.ones(1, ).to(dev))  # (1,)

            now_lr = [param_group['lr'] for param_group in pra_optimizer.param_groups][0]
            my_print(
                '|{}|{:>20}|\tIteration:{:>5}|\tLoss:{:.8f}|lr: {}|'.format(datetime.now(), pra_epoch_log, iteration,
                                                                            total_loss.data.item(), now_lr), log_file)
            loss_per_iteration.append(total_loss.data.item())
            pra_optimizer.zero_grad()
            total_loss.backward()
            pra_optimizer.step()

        # writer.add_scalar(f'{pra_epoch_log}_Iteration/loss', np.mean(loss_per_iteration), iteration)


def train_model_save_weights(pra_model, pra_data_loader, pra_optimizer, pra_epoch_log, current_epoch):
    # writer
    # writer = SummaryWriter()
    # pra_model.to(dev)
    pra_model.train()
    rescale_xy = torch.ones((1, 2, 1, 1)).to(dev)
    rescale_xy[:, 0] = max_x
    rescale_xy[:, 1] = max_y



    # train model using training data
    for iteration, (ori_data, A, _) in enumerate(pra_data_loader):
        # print(iteration, ori_data.shape, A.shape)
        # ori_data: (N, C, T, V)
        # C = [Vehicle_ID,Frame_ID,Total_Frames,Global_Time,Local_X,Local_Y,Global_X,Global_Y,v_Length,v_Width,v_Class,
        # v_Vel,v_Acc,Lane_ID,Preceding,Following,Space_Headway,Time_Headway] + [mask]
        data, no_norm_loc_data, object_type = preprocess_data(ori_data, rescale_xy)

        loss_per_iteration = []
        for now_history_frames in range(1, data.shape[-2]):
            input_data = data[:, :, :now_history_frames, :]  # (N, C, T, V) = (N, 11, 6, 120)
            output_loc_GT = data[:, :2, now_history_frames:, :]  # (N, C, T, V)=(N, 2, 6, 120)
            output_mask = data[:, -1:, now_history_frames:, :]  # (N, C, T, V)=(N, 1, 6, 120)

            A = A.float().to(dev)

            if current_epoch == 49 and iteration == (len(pra_data_loader) - 1) and now_history_frames == (data.shape[-2]-1):

                if not os.path.exists(f'./trainable_graph/{current_epoch}_epoch/'):
                    os.makedirs(f'./trainable_graph/{current_epoch}_epoch/')

                # Save input data
                torch.save(input_data,f'./trainable_graph/{current_epoch}_epoch/input.pt')
                torch.save(output_loc_GT, f'./trainable_graph/{current_epoch}_epoch/output_loc_GT.pt')
                torch.save(output_mask, f'./trainable_graph/{current_epoch}_epoch/output_mask.pt')
                torch.save(output_mask, f'./trainable_graph/{current_epoch}_epoch/Adjacency.pt')

                predicted = pra_model(pra_x=input_data, pra_A=A, pra_pred_length=output_loc_GT.shape[-2],
                                      pra_teacher_forcing_ratio=0,
                                      pra_teacher_location=output_loc_GT,graph = None, replace_graph = [False, False, False],
                                      save_graph = True, save_grap_path = f'./trainable_graph/{current_epoch}_epoch/')  # (N, C, T, V)=(N, 2, 6, 120)
            else:
                predicted = pra_model(pra_x=input_data, pra_A=A, pra_pred_length=output_loc_GT.shape[-2],
                                      pra_teacher_forcing_ratio=0,
                                      pra_teacher_location=output_loc_GT)  # (N, C, T, V)=(N, 2, 6, 120)


            ########################################################
            # Compute loss for training
            ########################################################
            # We use abs to compute loss to backward update weights
            # (N, T), (N, T)
            overall_sum_time, overall_num, _ = compute_RMSE(predicted, output_loc_GT, output_mask, pra_error_order=1)
            # overall_loss
            total_loss = torch.sum(overall_sum_time) / torch.max(torch.sum(overall_num),torch.ones(1, ).to(dev))  # (1,)

            now_lr = [param_group['lr'] for param_group in pra_optimizer.param_groups][0]
            my_print(
                '|{}|{:>20}|\tIteration:{:>5}|\tLoss:{:.8f}|lr: {}|'.format(datetime.now(), pra_epoch_log, iteration,
                                                                            total_loss.data.item(), now_lr), log_file)
            loss_per_iteration.append(total_loss.data.item())
            pra_optimizer.zero_grad()
            total_loss.backward()
            pra_optimizer.step()

    if current_epoch == 49:
        pra_model.save_weights(49)

        # writer.add_scalar(f'{pra_epoch_log}_Iteration/loss', np.mean(loss_per_iteration), iteration)


def val_model_replace_param(pra_model, pra_data_loader, replace_graph: bool, replace_params: bool):
    # pra_model.to(dev)
    pra_model.eval()
    rescale_xy = torch.ones((1, 2, 1, 1)).to(dev)
    rescale_xy[:, 0] = max_x
    rescale_xy[:, 1] = max_y
    all_overall_sum_list = []
    all_overall_num_list = []

    # train model using training data
    for iteration, (ori_data, A, _) in enumerate(pra_data_loader):
        # data: (N, C, T, V)
        # C = [Vehicle_ID,Frame_ID,Total_Frames,Global_Time,Local_X,Local_Y,Global_X,Global_Y,v_Length,v_Width,v_Class,
        # v_Vel,v_Acc,Lane_ID,Preceding,Following,Space_Headway,Time_Headway]  + [mask]
        data, no_norm_loc_data, _ = preprocess_data(ori_data, rescale_xy)

        for now_history_frames in range(6, 7):
            input_data = data[:, :, :now_history_frames, :]  # (N, C, T, V)=(N, 4, 6, 120)
            output_loc_GT = data[:, :2, now_history_frames:, :]  # (N, C, T, V)=(N, 2, 6, 120)
            output_mask = data[:, -1:, now_history_frames:, :]  # (N, C, T, V)=(N, 1, 6, 120)

            ori_output_loc_GT = no_norm_loc_data[:, :2, now_history_frames:, :]
            ori_output_last_loc = no_norm_loc_data[:, :2, now_history_frames - 1:now_history_frames, :]

            # for category
            cat_mask = ori_data[:, 10:11, now_history_frames:, :]  # (N, C, T, V)=(N, 1, 6, 120)

            A = A.float().to(dev)

            if replace_params:
                pra_model.load_weights(49)

            if replace_graph:
                conv1_graph = torch.load(f'./trainable_graph/49_epoch/1_conv_block_graph.graph')
                conv2_graph = torch.load(f'./trainable_graph/49_epoch/2_conv_block_graph.graph')
                conv3_graph = torch.load(f'./trainable_graph/49_epoch/3_conv_block_graph.graph')

                predicted = pra_model(pra_x=input_data, pra_A=A, pra_pred_length=output_loc_GT.shape[-2],
                                      pra_teacher_forcing_ratio=0,
                                      pra_teacher_location=output_loc_GT, graph = [conv1_graph, conv2_graph, conv3_graph],
                                      replace_graph = [True,True,True],save_graph = False, save_graph_path = None)  # (N, C, T, V)=(N, 2, 6, 120)
            else:
                predicted = pra_model(pra_x=input_data, pra_A=A, pra_pred_length=output_loc_GT.shape[-2],
                                      pra_teacher_forcing_ratio=0,
                                      pra_teacher_location=output_loc_GT)

                ########################################################
            # Compute details for training
            ########################################################
            predicted = predicted * rescale_xy
            # output_loc_GT = output_loc_GT*rescale_xy

            for ind in range(1, predicted.shape[-2]):
                predicted[:, :, ind] = torch.sum(predicted[:, :, ind - 1:ind + 1], dim=-2)
            predicted += ori_output_last_loc

            ### overall dist
            # overall_sum_time, overall_num, x2y2 = compute_RMSE(predicted, output_loc_GT, output_mask)
            overall_sum_time, overall_num, x2y2 = compute_RMSE(predicted, ori_output_loc_GT, output_mask)
            # all_overall_sum_list.extend(overall_sum_time.detach().cpu().numpy())
            all_overall_num_list.extend(overall_num.detach().cpu().numpy())
            # x2y2 (N, 6, 39)
            now_x2y2 = x2y2.detach().cpu().numpy()
            now_x2y2 = now_x2y2.sum(axis=-1)
            all_overall_sum_list.extend(now_x2y2)

    all_overall_sum_list = np.array(all_overall_sum_list)
    all_overall_num_list = np.array(all_overall_num_list)
    return all_overall_sum_list, all_overall_num_list


def val_model(pra_model, pra_data_loader):
    # pra_model.to(dev)
    pra_model.eval()
    rescale_xy = torch.ones((1, 2, 1, 1)).to(dev)
    rescale_xy[:, 0] = max_x
    rescale_xy[:, 1] = max_y
    all_overall_sum_list = []
    all_overall_num_list = []

    # train model using training data
    for iteration, (ori_data, A, _) in enumerate(pra_data_loader):
        # data: (N, C, T, V)
        # C = [Vehicle_ID,Frame_ID,Total_Frames,Global_Time,Local_X,Local_Y,Global_X,Global_Y,v_Length,v_Width,v_Class,
        # v_Vel,v_Acc,Lane_ID,Preceding,Following,Space_Headway,Time_Headway]  + [mask]
        data, no_norm_loc_data, _ = preprocess_data(ori_data, rescale_xy)

        for now_history_frames in range(6, 7):
            input_data = data[:, :, :now_history_frames, :]  # (N, C, T, V)=(N, 4, 6, 120)
            output_loc_GT = data[:, :2, now_history_frames:, :]  # (N, C, T, V)=(N, 2, 6, 120)
            output_mask = data[:, -1:, now_history_frames:, :]  # (N, C, T, V)=(N, 1, 6, 120)

            ori_output_loc_GT = no_norm_loc_data[:, :2, now_history_frames:, :]
            ori_output_last_loc = no_norm_loc_data[:, :2, now_history_frames - 1:now_history_frames, :]

            # for category
            cat_mask = ori_data[:, 10:11, now_history_frames:, :]  # (N, C, T, V)=(N, 1, 6, 120)

            A = A.float().to(dev)
            predicted = pra_model(pra_x=input_data, pra_A=A, pra_pred_length=output_loc_GT.shape[-2],
                                  pra_teacher_forcing_ratio=0,
                                  pra_teacher_location=output_loc_GT)  # (N, C, T, V)=(N, 2, 6, 120)
            ########################################################
            # Compute details for training
            ########################################################
            predicted = predicted * rescale_xy
            # output_loc_GT = output_loc_GT*rescale_xy

            for ind in range(1, predicted.shape[-2]):
                predicted[:, :, ind] = torch.sum(predicted[:, :, ind - 1:ind + 1], dim=-2)
            predicted += ori_output_last_loc

            ### overall dist
            # overall_sum_time, overall_num, x2y2 = compute_RMSE(predicted, output_loc_GT, output_mask)
            overall_sum_time, overall_num, x2y2 = compute_RMSE(predicted, ori_output_loc_GT, output_mask)
            # all_overall_sum_list.extend(overall_sum_time.detach().cpu().numpy())
            all_overall_num_list.extend(overall_num.detach().cpu().numpy())
            # x2y2 (N, 6, 39)
            now_x2y2 = x2y2.detach().cpu().numpy()
            now_x2y2 = now_x2y2.sum(axis=-1)
            all_overall_sum_list.extend(now_x2y2)

    all_overall_sum_list = np.array(all_overall_sum_list)
    all_overall_num_list = np.array(all_overall_num_list)
    return all_overall_sum_list, all_overall_num_list


def val_model_save_graph(pra_model, pra_data_loader):
    # pra_model.to(dev)

    # load pre-trained params
    params = torch.load('./trained_models/ngsim_0-6mins_model_epoch_0049.pt')

    state_dicts_list = []
    for _index,_part in enumerate(pra_model.st_gcn_networks):
        _temp_dict = {}
        for _state_key in _part.state_dict().keys():
            _temp_dict[_state_key] = params['xin_graph_seq2seq_model'][f'st_gcn_networks.{_index}.' + _state_key]

        pra_model.st_gcn_networks[_index].load_state_dict(_temp_dict)


    pra_model.eval()
    rescale_xy = torch.ones((1, 2, 1, 1)).to(dev)
    rescale_xy[:, 0] = max_x
    rescale_xy[:, 1] = max_y
    all_overall_sum_list = []
    all_overall_num_list = []

    # train model using training data
    for iteration, (ori_data, A, _) in enumerate(pra_data_loader):
        # data: (N, C, T, V)
        # C = [Vehicle_ID,Frame_ID,Total_Frames,Global_Time,Local_X,Local_Y,Global_X,Global_Y,v_Length,v_Width,v_Class,
        # v_Vel,v_Acc,Lane_ID,Preceding,Following,Space_Headway,Time_Headway]  + [mask]
        data, no_norm_loc_data, _ = preprocess_data(ori_data, rescale_xy)

        for now_history_frames in range(6, 7):
            input_data = data[:, :, :now_history_frames, :]  # (N, C, T, V)=(N, 4, 6, 120)
            output_loc_GT = data[:, :2, now_history_frames:, :]  # (N, C, T, V)=(N, 2, 6, 120)
            output_mask = data[:, -1:, now_history_frames:, :]  # (N, C, T, V)=(N, 1, 6, 120)

            ori_output_loc_GT = no_norm_loc_data[:, :2, now_history_frames:, :]
            ori_output_last_loc = no_norm_loc_data[:, :2, now_history_frames - 1:now_history_frames, :]

            # for category
            cat_mask = ori_data[:, 10:11, now_history_frames:, :]  # (N, C, T, V)=(N, 1, 6, 120)

            A = A.float().to(dev)
            predicted = pra_model(pra_x=input_data, pra_A=A, pra_pred_length=output_loc_GT.shape[-2],
                                  pra_teacher_forcing_ratio=0,
                                  pra_teacher_location=output_loc_GT,save_graph=True,save_graph_path = f'./trainable_graph/49_epoch/{iteration}_val_graph')  # (N, C, T, V)=(N, 2, 6, 120)
            ########################################################
            # Compute details for training
            ########################################################
            predicted = predicted * rescale_xy
            # output_loc_GT = output_loc_GT*rescale_xy

            for ind in range(1, predicted.shape[-2]):
                predicted[:, :, ind] = torch.sum(predicted[:, :, ind - 1:ind + 1], dim=-2)
            predicted += ori_output_last_loc

            ### overall dist
            # overall_sum_time, overall_num, x2y2 = compute_RMSE(predicted, output_loc_GT, output_mask)
            overall_sum_time, overall_num, x2y2 = compute_RMSE(predicted, ori_output_loc_GT, output_mask)
            # all_overall_sum_list.extend(overall_sum_time.detach().cpu().numpy())
            all_overall_num_list.extend(overall_num.detach().cpu().numpy())
            # x2y2 (N, 6, 39)
            now_x2y2 = x2y2.detach().cpu().numpy()
            now_x2y2 = now_x2y2.sum(axis=-1)
            all_overall_sum_list.extend(now_x2y2)

    all_overall_sum_list = np.array(all_overall_sum_list)
    all_overall_num_list = np.array(all_overall_num_list)
    return all_overall_sum_list, all_overall_num_list


def val_model_load_graph(pra_model, pra_data_loader):
    # pra_model.to(dev)

    # load pre-trained params
    params = torch.load('./trained_models/model_epoch_0049.pt')


    # state_dicts_list = []
    # _count = 0
    # for _index,_part in enumerate(pra_model.st_gcn_networks):
    #     _temp_dict = {}
    #     for _state_key in _part.state_dict().keys():
    #         _temp_dict[_state_key] = params['xin_graph_seq2seq_model'][f'st_gcn_networks.{_index}.' + _state_key]
    #         _count += 1
    #     pra_model.st_gcn_networks[_index].load_state_dict(_temp_dict)
    #
    # _temp_dict = {}
    # for _,_part in enumerate(pra_model.seq2seq_car.state_dict().keys()):
    #     _temp_dict[_part] = params['xin_graph_seq2seq_model'][f'seq2seq_car.{_part}']
    #     _count += 1
    #
    # pra_model.seq2seq_car.load_state_dict(_temp_dict)
    #
    # _temp_dict = {}
    # for _,_part in enumerate(pra_model.seq2seq_human.state_dict().keys()):
    #     _temp_dict[_part] = params['xin_graph_seq2seq_model'][f'seq2seq_car.{_part}']
    #     _count += 1
    #
    # pra_model.seq2seq_human.load_state_dict(_temp_dict)
    #
    # _temp_dict = {}
    # for _,_part in enumerate(pra_model.seq2seq_bike.state_dict().keys()):
    #     _temp_dict[_part] = params['xin_graph_seq2seq_model'][f'seq2seq_car.{_part}']
    #     _count += 1
    #
    # pra_model.seq2seq_bike.load_state_dict(_temp_dict)
    #
    # _edge_import = {}
    # _edge_import['0'] = params['xin_graph_seq2seq_model']['edge_importance.0']
    # _edge_import['1'] = params['xin_graph_seq2seq_model']['edge_importance.1']
    # _edge_import['2'] = params['xin_graph_seq2seq_model']['edge_importance.2']
    # _edge_import['3'] = params['xin_graph_seq2seq_model']['edge_importance.3']
    #
    # pra_model.edge_importance.load_state_dict(_edge_import)

    _temp_dict = {}
    for _part in pra_model.state_dict().keys():
        if 'st_gcn_networks' in _part:
            _temp_dict[_part.split('st_gcn_networks')[-1][1:]] = params['xin_graph_seq2seq_model'][_part]

    pra_model.st_gcn_networks.load_state_dict(_temp_dict)

    pra_model.eval()
    rescale_xy = torch.ones((1, 2, 1, 1)).to(dev)
    rescale_xy[:, 0] = max_x
    rescale_xy[:, 1] = max_y
    all_overall_sum_list = []
    all_overall_num_list = []

    # train model using training data
    for iteration, (ori_data, A, _) in enumerate(pra_data_loader):
        # data: (N, C, T, V)
        # C = [Vehicle_ID,Frame_ID,Total_Frames,Global_Time,Local_X,Local_Y,Global_X,Global_Y,v_Length,v_Width,v_Class,
        # v_Vel,v_Acc,Lane_ID,Preceding,Following,Space_Headway,Time_Headway]  + [mask]
        data, no_norm_loc_data, _ = preprocess_data(ori_data, rescale_xy)

        for now_history_frames in range(6, 7):
            input_data = data[:, :, :now_history_frames, :]  # (N, C, T, V)=(N, 4, 6, 120)
            output_loc_GT = data[:, :2, now_history_frames:, :]  # (N, C, T, V)=(N, 2, 6, 120)
            output_mask = data[:, -1:, now_history_frames:, :]  # (N, C, T, V)=(N, 1, 6, 120)

            ori_output_loc_GT = no_norm_loc_data[:, :2, now_history_frames:, :]
            ori_output_last_loc = no_norm_loc_data[:, :2, now_history_frames - 1:now_history_frames, :]

            # for category
            cat_mask = ori_data[:, 10:11, now_history_frames:, :]  # (N, C, T, V)=(N, 1, 6, 120)

            A = A.float().to(dev)
            predicted = pra_model(pra_x=input_data, pra_A=A, pra_pred_length=output_loc_GT.shape[-2],
                                  pra_teacher_forcing_ratio=0,
                                  pra_teacher_location=output_loc_GT,graph=[torch.load(f'./trainable_graph/49_epoch/{iteration}_val_graph0_conv_block_graph.graph'),
                                                                            torch.load(f'./trainable_graph/49_epoch/{iteration}_val_graph1_conv_block_graph.graph'),
                                                                            torch.load(f'./trainable_graph/49_epoch/{iteration}_val_graph2_conv_block_graph.graph')],replace_graph=[False,False,False])  # (N, C, T, V)=(N, 2, 6, 120)
            ########################################################
            # Compute details for training
            ########################################################
            predicted = predicted * rescale_xy
            # output_loc_GT = output_loc_GT*rescale_xy

            for ind in range(1, predicted.shape[-2]):
                predicted[:, :, ind] = torch.sum(predicted[:, :, ind - 1:ind + 1], dim=-2)
            predicted += ori_output_last_loc

            ### overall dist
            # overall_sum_time, overall_num, x2y2 = compute_RMSE(predicted, output_loc_GT, output_mask)
            overall_sum_time, overall_num, x2y2 = compute_RMSE(predicted, ori_output_loc_GT, output_mask)
            # all_overall_sum_list.extend(overall_sum_time.detach().cpu().numpy())
            all_overall_num_list.extend(overall_num.detach().cpu().numpy())
            # x2y2 (N, 6, 39)
            now_x2y2 = x2y2.detach().cpu().numpy()
            now_x2y2 = now_x2y2.sum(axis=-1)
            all_overall_sum_list.extend(now_x2y2)

    all_overall_sum_list = np.array(all_overall_sum_list)
    all_overall_num_list = np.array(all_overall_num_list)
    return all_overall_sum_list, all_overall_num_list


def val_two_models_load_graph(fresh_model, trained_model,partially_trained_model, pra_data_loader):
    # pra_model.to(dev)

    import copy
    partially_trained_model = copy.deepcopy(fresh_model)
    trained_model = copy.deepcopy(fresh_model)

    # load pre-trained params
    params = torch.load('./trained_models/ngsim_0-6mins_model_epoch_0049.pt')

    _count = 0
    _temp_keys = [x for x in params['xin_graph_seq2seq_model'].keys() if f'st_gcn_networks' in x]
    _temp_dict = { x[16:] : params['xin_graph_seq2seq_model'][x] for x in _temp_keys}
    partially_trained_model.st_gcn_networks.load_state_dict(_temp_dict)

    _temp_dict = {}
    for _,_part in enumerate(trained_model.seq2seq_car.state_dict().keys()):
        _temp_dict[_part] = params['xin_graph_seq2seq_model'][f'seq2seq_car.{_part}']
        _count += 1
    #
    partially_trained_model.seq2seq_car.load_state_dict(_temp_dict)

    _temp_dict = {}
    for _,_part in enumerate(trained_model.seq2seq_human.state_dict().keys()):
        _temp_dict[_part] = params['xin_graph_seq2seq_model'][f'seq2seq_human.{_part}']
        _count += 1

    partially_trained_model.seq2seq_human.load_state_dict(_temp_dict)
    #
    # _temp_dict = {}
    # for _,_part in enumerate(trained_model.seq2seq_bike.state_dict().keys()):
    #     _temp_dict[_part] = params['xin_graph_seq2seq_model'][f'seq2seq_bike.{_part}']
    #     _count += 1
    #
    # partially_trained_model.seq2seq_bike.load_state_dict(_temp_dict)

    _edge_import = {}
    _edge_import['0'] = params['xin_graph_seq2seq_model']['edge_importance.0']
    _edge_import['1'] = params['xin_graph_seq2seq_model']['edge_importance.1']
    _edge_import['2'] = params['xin_graph_seq2seq_model']['edge_importance.2']
    _edge_import['3'] = params['xin_graph_seq2seq_model']['edge_importance.3']

    partially_trained_model.edge_importance.load_state_dict(_edge_import)

    trained_model.load_state_dict(params['xin_graph_seq2seq_model'])

    trained_model.eval()
    fresh_model.eval()
    partially_trained_model.eval()

    rescale_xy = torch.ones((1, 2, 1, 1)).to(dev)
    rescale_xy[:, 0] = max_x
    rescale_xy[:, 1] = max_y

    trained_all_overall_sum_list = []
    trained_all_overall_num_list = []

    fresh_all_overall_sum_list = []
    fresh_all_overall_num_list = []

    replaced_graph_all_overall_sum_list = []
    replaced_graph_all_overall_num_list = []

    partially_trained_all_overall_sum_list = []
    partially_trained_all_overall_num_list = []

    # train model using training data
    for iteration, (ori_data, A, _) in enumerate(pra_data_loader):
        # data: (N, C, T, V)
        # C = [Vehicle_ID,Frame_ID,Total_Frames,Global_Time,Local_X,Local_Y,Global_X,Global_Y,v_Length,v_Width,v_Class,
        # v_Vel,v_Acc,Lane_ID,Preceding,Following,Space_Headway,Time_Headway]  + [mask]
        data, no_norm_loc_data, _ = preprocess_data(ori_data, rescale_xy)

        for now_history_frames in range(6, 7):
            input_data = data[:, :, :now_history_frames, :]  # (N, C, T, V)=(N, 4, 6, 120)
            output_loc_GT = data[:, :2, now_history_frames:, :]  # (N, C, T, V)=(N, 2, 6, 120)
            output_mask = data[:, -1:, now_history_frames:, :]  # (N, C, T, V)=(N, 1, 6, 120)

            ori_output_loc_GT = no_norm_loc_data[:, :2, now_history_frames:, :]
            ori_output_last_loc = no_norm_loc_data[:, :2, now_history_frames - 1:now_history_frames, :]

            # for category
            cat_mask = ori_data[:, 10:11, now_history_frames:, :]  # (N, C, T, V)=(N, 1, 6, 120)

            A = A.float().to(dev)
            fresh_predicted, fresh_graph_list = fresh_model(pra_x=input_data, pra_A=A, pra_pred_length=output_loc_GT.shape[-2],
                                  pra_teacher_forcing_ratio=0,
                                  pra_teacher_location=output_loc_GT)  # (N, C, T, V)=(N, 2, 6, 120)

            trained_predicted, graph_list = trained_model(pra_x=input_data, pra_A=A, pra_pred_length=output_loc_GT.shape[-2],
                                  pra_teacher_forcing_ratio=0,
                                  pra_teacher_location=output_loc_GT)

            torch.save(graph_list,'./trainable_graph/graph_list.graph')

            replaced_graph_predicted, replaced_graph_list = fresh_model(pra_x=input_data, pra_A=A, pra_pred_length=output_loc_GT.shape[-2],
                                  pra_teacher_forcing_ratio=0,
                                  pra_teacher_location=output_loc_GT, graph = graph_list, replace_graph = [False, False, True])

            partially_trained_predicted, partially_trained_graph_list = partially_trained_model(pra_x=input_data, pra_A=A, pra_pred_length=output_loc_GT.shape[-2],
                                  pra_teacher_forcing_ratio=0,
                                  pra_teacher_location=output_loc_GT, graph = graph_list, replace_graph = [False, False, True])
            ########################################################
            # Compute details for training
            ########################################################
            fresh_predicted = fresh_predicted * rescale_xy
            trained_predicted = trained_predicted * rescale_xy
            replaced_graph_predicted = replaced_graph_predicted * rescale_xy
            partially_trained_predicted = partially_trained_predicted * rescale_xy

            # predicted = predicted * rescale_xy

            # output_loc_GT = output_loc_GT*rescale_xy
            for ind in range(1, fresh_predicted.shape[-2]):
                fresh_predicted[:, :, ind] = torch.sum(fresh_predicted[:, :, ind - 1:ind + 1], dim=-2)
            fresh_predicted += ori_output_last_loc

            for ind in range(1, trained_predicted.shape[-2]):
                trained_predicted[:, :, ind] = torch.sum(trained_predicted[:, :, ind - 1:ind + 1], dim=-2)
            trained_predicted += ori_output_last_loc

            for ind in range(1, replaced_graph_predicted.shape[-2]):
                replaced_graph_predicted[:, :, ind] = torch.sum(replaced_graph_predicted[:, :, ind - 1:ind + 1], dim=-2)
            replaced_graph_predicted += ori_output_last_loc

            for ind in range(1, partially_trained_predicted.shape[-2]):
                partially_trained_predicted[:, :, ind] = torch.sum(partially_trained_predicted[:, :, ind - 1:ind + 1], dim=-2)
            partially_trained_predicted += ori_output_last_loc
            # for ind in range(1, predicted.shape[-2]):
            #     predicted[:, :, ind] = torch.sum(predicted[:, :, ind - 1:ind + 1], dim=-2)
            # predicted += ori_output_last_loc

            ### overall dist
            # overall_sum_time, overall_num, x2y2 = compute_RMSE(predicted, output_loc_GT, output_mask)
            # overall_sum_time, overall_num, x2y2 = compute_RMSE(predicted, ori_output_loc_GT, output_mask)
            trained_overall_sum_time, trained_overall_num, trained_x2y2 = compute_RMSE(trained_predicted, ori_output_loc_GT, output_mask)
            fresh_overall_sum_time, fresh_overall_num, fresh_x2y2 = compute_RMSE(fresh_predicted, ori_output_loc_GT, output_mask)
            replaced_graph_overall_sum_time, replaced_graph_overall_num, replaced_graph_x2y2 = compute_RMSE(replaced_graph_predicted, ori_output_loc_GT, output_mask)
            partially_trained_overall_sum_time, partially_trained_overall_num, partially_trained_x2y2 = compute_RMSE(partially_trained_predicted, ori_output_loc_GT, output_mask)
            # all_overall_sum_list.extend(overall_sum_time.detach().cpu().numpy())
            trained_all_overall_num_list.extend(trained_overall_num.detach().cpu().numpy())
            # x2y2 (N, 6, 39)
            trained_now_x2y2 = trained_x2y2.detach().cpu().numpy()
            trained_now_x2y2 = trained_now_x2y2.sum(axis=-1)
            trained_all_overall_sum_list.extend(trained_now_x2y2)

            # all_overall_sum_list.extend(overall_sum_time.detach().cpu().numpy())
            fresh_all_overall_num_list.extend(fresh_overall_num.detach().cpu().numpy())
            # x2y2 (N, 6, 39)
            fresh_now_x2y2 = fresh_x2y2.detach().cpu().numpy()
            fresh_now_x2y2 = fresh_now_x2y2.sum(axis=-1)
            fresh_all_overall_sum_list.extend(fresh_now_x2y2)

            # all_overall_sum_list.extend(overall_sum_time.detach().cpu().numpy())
            replaced_graph_all_overall_num_list.extend(replaced_graph_overall_num.detach().cpu().numpy())
            # x2y2 (N, 6, 39)
            replaced_graph_now_x2y2 = replaced_graph_x2y2.detach().cpu().numpy()
            replaced_graph_now_x2y2 = replaced_graph_now_x2y2.sum(axis=-1)
            replaced_graph_all_overall_sum_list.extend(replaced_graph_now_x2y2)

            # all_overall_sum_list.extend(overall_sum_time.detach().cpu().numpy())
            partially_trained_all_overall_num_list.extend(partially_trained_overall_num.detach().cpu().numpy())
            # x2y2 (N, 6, 39)
            partially_trained_now_x2y2 = partially_trained_x2y2.detach().cpu().numpy()
            partially_trained_now_x2y2 = partially_trained_now_x2y2.sum(axis=-1)
            partially_trained_all_overall_sum_list.extend(partially_trained_now_x2y2)



    trained_all_overall_sum_list = np.array(trained_all_overall_sum_list)
    trained_all_overall_num_list = np.array(trained_all_overall_num_list)

    fresh_all_overall_sum_list = np.array(fresh_all_overall_sum_list)
    fresh_all_overall_num_list = np.array(fresh_all_overall_num_list)

    replaced_graph_all_overall_sum_list = np.array(replaced_graph_all_overall_sum_list)
    replaced_graph_all_overall_num_list = np.array(replaced_graph_all_overall_num_list)

    partially_trained_all_overall_sum_list = np.array(partially_trained_all_overall_sum_list)
    partially_trained_all_overall_num_list = np.array(partially_trained_all_overall_num_list)

    return trained_all_overall_sum_list, trained_all_overall_num_list, \
           fresh_all_overall_sum_list, fresh_all_overall_num_list, \
           replaced_graph_all_overall_sum_list, replaced_graph_all_overall_num_list, \
           partially_trained_all_overall_sum_list, partially_trained_all_overall_num_list


def run_trainval_replace_params(pra_model, pra_traindata_path, pra_testdata_path, graph_args):
    loader_train = data_loader(pra_traindata_path, graph_args, pra_batch_size=batch_size_train, pra_shuffle=True,
                               pra_drop_last=True, train_val_test='train')
    # loader_test = data_loader(pra_testdata_path, pra_batch_size=batch_size_train, pra_shuffle=True, pra_drop_last=True,
    #                           train_val_test='all')

    # evaluate on testing data (observe 5 frame and predict 1 frame)
    loader_val = data_loader(pra_traindata_path, graph_args, pra_batch_size=batch_size_val, pra_shuffle=False, pra_drop_last=False,
                             train_val_test='val')

    optimizer = optim.Adam([{'params': pra_model.parameters()}, ], )  # lr = 0.0001)

    # for now_epoch in range(total_epoch):
        # all_loader_train = itertools.chain(loader_train, loader_test)

        # my_print('#     - Train -    #', log_file)

        # train_model(pra_model, loader_train, pra_optimizer=optimizer,
        #             pra_epoch_log='Epoch:{:>4}/{:>4}'.format(now_epoch, total_epoch))

        # train_model_save_weights(pra_model, loader_train, pra_optimizer=optimizer,
        #             pra_epoch_log='Epoch:{:>4}/{:>4}'.format(now_epoch, total_epoch), current_epoch=now_epoch)

        # my_save_model(pra_model, now_epoch, work_dir)

    my_print('#     - Test -    #', log_file)

    display_result(
            val_model_load_graph(pra_model, loader_val), log_file,
            pra_pref='{}_Epoch{}'.format('Val', 0)
        )
        # if now_epoch == 1:
        #     display_result(
        #         val_model_replace_param(pra_model, loader_val, True,False), log_file,
        #         pra_pref='{}_Epoch{}'.format('Val', now_epoch)
        #     )
        # else:
        #     display_result(
        #         val_model_replace_param(pra_model, loader_val,False, False), log_file,
        #         pra_pref='{}_Epoch{}'.format('Val', now_epoch)
        #     )


def run_trainval_replace_params_two_model(fresh_model, trained_model, partially_trained_model,pra_traindata_path, pra_testdata_path, graph_args):
    loader_train = data_loader(pra_traindata_path, graph_args, pra_batch_size=batch_size_train, pra_shuffle=True,
                               pra_drop_last=True, train_val_test='train')
    # loader_test = data_loader(pra_testdata_path, pra_batch_size=batch_size_train, pra_shuffle=True, pra_drop_last=True,
    #                           train_val_test='all')

    # evaluate on testing data (observe 5 frame and predict 1 frame)
    loader_val = data_loader(pra_traindata_path, graph_args, pra_batch_size=batch_size_val, pra_shuffle=False, pra_drop_last=False,
                             train_val_test='val')

    optimizer = optim.Adam([{'params': fresh_model.parameters()}, ], )  # lr = 0.0001)

    for now_epoch in range(total_epoch):
        # all_loader_train = itertools.chain(loader_train, loader_test)

        my_print('#     - Train -    #', log_file)

        train_model_weight_returned_graphs(fresh_model, loader_train, pra_optimizer=optimizer,
                    pra_epoch_log='Epoch:{:>4}/{:>4}'.format(now_epoch, total_epoch))

        _, _S, _ = np.linalg.svd(fresh_model.state_dict()['st_gcn_networks.1.gcn.conv.weight'][:, :, 0, 0].cpu().numpy())
        print("***")
        print(_S)
        print("***")
        # train_model_save_weights(pra_model, loader_train, pra_optimizer=optimizer,
        #             pra_epoch_log='Epoch:{:>4}/{:>4}'.format(now_epoch, total_epoch), current_epoch=now_epoch)

        # my_save_model(pra_model, now_epoch, work_dir)

    my_print('#     - running on val data -    #', log_file)

    trained_all_overall_sum_list, trained_all_overall_num_list, \
    fresh_all_overall_sum_list, fresh_all_overall_num_list, \
    replaced_graph_all_overall_sum_list, replaced_graph_all_overall_num_list, \
    partially_trained_all_overall_sum_list, partially_trained_all_overall_num_list = val_two_models_load_graph(fresh_model, trained_model, partially_trained_model,loader_val)

    display_result(
            [trained_all_overall_sum_list,trained_all_overall_num_list],  log_file,
            pra_pref='{}_trained_{}'.format('Train', 0)
        )

    display_result(
            [fresh_all_overall_sum_list,fresh_all_overall_num_list],  log_file,
            pra_pref='{}_fresh_{}'.format('Train', 0)
        )

    display_result(
            [replaced_graph_all_overall_sum_list,replaced_graph_all_overall_num_list],  log_file,
            pra_pref='{}_replaced_graph_{}'.format('Train', 0)
        )

    display_result(
            [partially_trained_all_overall_sum_list,partially_trained_all_overall_num_list],  log_file,
            pra_pref='{}_partially_trained_{}'.format('Train', 0)
        )


def run_trainval_select_clients(pra_model, pra_traindata_path, pra_valdata_path, drop_ratio, graph_args):

    if isinstance(pra_traindata_path, list):
        loader_train = []
        for _path in pra_traindata_path:
            loader_train.append(
                data_loader_with_drop(_path, drop_ratio, 1, graph_args, pra_batch_size=batch_size_train,
                                      pra_shuffle=True,
                                      pra_drop_last=True, train_val_test='train')
            )
    else:
        loader_train = data_loader_with_drop(pra_traindata_path, drop_ratio, 1, graph_args, pra_batch_size=batch_size_train, pra_shuffle=True,
                               pra_drop_last=True, train_val_test='train')

    # loader_train = data_loader_with_drop(pra_traindata_path, drop_ratio, 1, graph_args, pra_batch_size=batch_size_train, pra_shuffle=True,
    #                            pra_drop_last=True, train_val_test='train')
    # loader_test = data_loader(pra_testdata_path, pra_batch_size=batch_size_train, pra_shuffle=True, pra_drop_last=True,
    #                           train_val_test='all')

    # evaluate on testing data (observe 5 frame and predict 1 frame)
    if isinstance(pra_valdata_path, list):
        loader_val = []
        for _path in pra_valdata_path:
            loader_val.append(
                data_loader_with_drop_se(_path, 0, 0, 1, graph_args,
                                         pra_batch_size=batch_size_train, pra_shuffle=True,
                                         pra_drop_last=True, train_val_test='train')
            )
    else:
        loader_val = data_loader_with_drop_se(pra_valdata_path, 0, 0, 1, graph_args, pra_batch_size=batch_size_train, pra_shuffle=True,
                                   pra_drop_last=True, train_val_test='train')

    optimizer = optim.Adam([{'params': pra_model.parameters()}, ], )  # lr = 0.0001)

    for now_epoch in range(total_epoch):
        # all_loader_train = itertools.chain(loader_train, loader_test)

        my_print('#     - Train -    #', log_file)
        if isinstance(pra_traindata_path, list):
            for _ind, _loader in enumerate(loader_train):
                # loader_train = data_loader_with_drop(_path, drop_ratio, 1, graph_args, pra_batch_size=batch_size_train,
                #                       pra_shuffle=True,
                #                       pra_drop_last=True, train_val_test='train')
                train_model(pra_model, _loader, pra_optimizer=optimizer,
                            pra_epoch_log='Epoch:{:>4}/{:>4}'.format(now_epoch, total_epoch))
        else:
            train_model(pra_model, loader_train, pra_optimizer=optimizer,
                        pra_epoch_log='Epoch:{:>4}/{:>4}'.format(now_epoch, total_epoch))
        # train_model_save_weights(pra_model, loader_train, pra_optimizer=optimizer,
        #             pra_epoch_log='Epoch:{:>4}/{:>4}'.format(now_epoch, total_epoch), current_epoch=now_epoch)
        if now_epoch == 49:
            # renamed_file = os.path.basename(pra_traindata_path).split('.')[0] + '_selected_clients_drop_1.0'
            renamed_file = '0-1_noised_drop_1.0'
            save_model(pra_model, now_epoch, renamed_file, work_dir)

        my_print('#     - Val -    #', log_file)

        if isinstance(pra_valdata_path, list):
            for _ind, _loader in enumerate(loader_val):
                # loader_val = data_loader_with_drop_se(_path, 0, 0, 1, graph_args,
                #                          pra_batch_size=batch_size_train, pra_shuffle=True,
                #                          pra_drop_last=True, train_val_test='train')
                display_result(
                    val_model(pra_model, _loader), log_file,
                    pra_pref='{}_Epoch{}'.format('Val', now_epoch)
                )
        else:
            display_result(
                val_model(pra_model, loader_val), log_file,
                pra_pref='{}_Epoch{}'.format('Val', now_epoch)
            )


def run_val_select_clients(pra_model, pra_traindata_path, pra_testdata_path, drop_ratio_start, drop_ratio_end, graph_args):

    if isinstance(pra_traindata_path, list):
        loader_train = []
        for _path in pra_traindata_path:
            loader_train.append(
                data_loader_with_drop_se(_path, drop_ratio_start, drop_ratio_end, 1, graph_args,
                                         pra_batch_size=batch_size_train, pra_shuffle=True,
                                         pra_drop_last=True, train_val_test='train')
            )
    else:
        loader_train = data_loader_with_drop_se(pra_traindata_path, drop_ratio_start, drop_ratio_end, 1, graph_args, pra_batch_size=batch_size_train, pra_shuffle=True,
                                   pra_drop_last=True, train_val_test='train')

    my_print('#     - Val -    #', log_file)
    if isinstance(pra_traindata_path, list):
        for _ind, _loader in enumerate(loader_train):
            display_result(
                    val_model(pra_model, _loader), log_file,
                    pra_pref='{}_Epoch{}'.format('Val', '_select_clients')
                )
    else:
        display_result(
            val_model(pra_model, loader_train), log_file,
            pra_pref='{}_Epoch{}'.format('Val', '_select_clients')
        )


def run_trainval(pra_model, pra_traindata_path, pra_testdata_path, graph_args):
    loader_train = data_loader(pra_traindata_path, graph_args, pra_batch_size=batch_size_train, pra_shuffle=True,
                               pra_drop_last=True, train_val_test='train')
    # loader_test = data_loader(pra_testdata_path, pra_batch_size=batch_size_train, pra_shuffle=True, pra_drop_last=True,
    #                           train_val_test='all')

    # evaluate on testing data (observe 5 frame and predict 1 frame)
    loader_val = data_loader(pra_traindata_path, graph_args, pra_batch_size=batch_size_val, pra_shuffle=False, pra_drop_last=False,
                             train_val_test='val')

    optimizer = optim.Adam([{'params': pra_model.parameters()}, ], )  # lr = 0.0001)

    for now_epoch in range(total_epoch):
        # all_loader_train = itertools.chain(loader_train, loader_test)

        my_print('#     - Train -    #', log_file)
        train_model(pra_model, loader_train, pra_optimizer=optimizer,
                    pra_epoch_log='Epoch:{:>4}/{:>4}'.format(now_epoch, total_epoch))
        # train_model_save_weights(pra_model, loader_train, pra_optimizer=optimizer,
        #             pra_epoch_log='Epoch:{:>4}/{:>4}'.format(now_epoch, total_epoch), current_epoch=now_epoch)
        if now_epoch == 49:
            renamed_file = os.path.basename(pra_traindata_path).split('.')[0]
            save_model(pra_model, now_epoch, renamed_file, work_dir)

        my_print('#     - Val -    #', log_file)

        display_result(
            val_model(pra_model, loader_val), log_file,
            pra_pref='{}_Epoch{}'.format('Val', now_epoch)
        )

        # print(f'SVD -- RESULT : {svd(np.mat(pra_model.st_gcn_networks[1].state_dict()["gcn.conv.weight"].cpu().numpy()))[1]}')


def run_explain(pra_model, pra_traindata_path, graph_args):

    # evaluate on testing data (observe 5 frame and predict 1 frame)
    loader_val = data_loader_with_Adj(pra_traindata_path, graph_args, pra_batch_size=1, pra_shuffle=False, pra_drop_last=False,
                             train_val_test='val')

    rescale_xy = torch.ones((1, 2, 1, 1)).to(dev)
    rescale_xy[:, 0] = max_x
    rescale_xy[:, 1] = max_y
    all_overall_sum_list = []
    all_overall_num_list = []

    # train model using training data
    for iteration, (ori_data, A, _, adjacency, now_adjacency) in enumerate(loader_val):
        # data: (N, C, T, V)
        # C = [Vehicle_ID,Frame_ID,Total_Frames,Global_Time,Local_X,Local_Y,Global_X,Global_Y,v_Length,v_Width,v_Class,
        # v_Vel,v_Acc,Lane_ID,Preceding,Following,Space_Headway,Time_Headway]  + [mask]
        data, no_norm_loc_data, _ = preprocess_data(ori_data, rescale_xy)

        for now_history_frames in range(6, 7):
            input_data = data[:, :, :now_history_frames, :]  # (N, C, T, V)=(N, 4, 6, 120)
            output_loc_GT = data[:, :2, now_history_frames:, :]  # (N, C, T, V)=(N, 2, 6, 120)
            output_mask = data[:, -1:, now_history_frames:, :]  # (N, C, T, V)=(N, 1, 6, 120)

            ori_output_loc_GT = no_norm_loc_data[:, :2, now_history_frames:, :]
            ori_output_last_loc = no_norm_loc_data[:, :2, now_history_frames - 1:now_history_frames, :]

            # for category
            # cat_mask = ori_data[:, 10:11, now_history_frames:, :]  # (N, C, T, V)=(N, 1, 6, 120)

            A = A.float().to(dev)
            predicted = pra_model(pra_x=input_data, pra_A=A, pra_pred_length=output_loc_GT.shape[-2],
                                  pra_teacher_forcing_ratio=0,
                                  pra_teacher_location=output_loc_GT)  # (N, C, T, V)=(N, 2, 6, 120)
            ########################################################
            # Compute details for training
            ########################################################
            predicted = predicted * rescale_xy
            # output_loc_GT = output_loc_GT*rescale_xy

            explainer = Explainer(pra_model, adjacency.clone().detach(), A.clone().detach(),
                                  input_data.clone().detach(), output_loc_GT.clone().detach(), predicted.clone().detach())
            explainer.explain(0)

            for ind in range(1, predicted.shape[-2]):
                predicted[:, :, ind] = torch.sum(predicted[:, :, ind - 1:ind + 1], dim=-2)
            predicted += ori_output_last_loc

            ### overall dist
            # overall_sum_time, overall_num, x2y2 = compute_RMSE(predicted, output_loc_GT, output_mask)
            overall_sum_time, overall_num, x2y2 = compute_RMSE(predicted, ori_output_loc_GT, output_mask)
            # all_overall_sum_list.extend(overall_sum_time.detach().cpu().numpy())
            all_overall_num_list.extend(overall_num.detach().cpu().numpy())
            # x2y2 (N, 6, 39)
            now_x2y2 = x2y2.detach().cpu().numpy()
            now_x2y2 = now_x2y2.sum(axis=-1)
            all_overall_sum_list.extend(now_x2y2)

    all_overall_sum_list = np.array(all_overall_sum_list)
    all_overall_num_list = np.array(all_overall_num_list)


def aggregate_att(w_clients, w_server, stepsize, metric, dp):
    """
    Attentive aggregation
    :param w_clients: list of client model parameters
    :param w_server: server model parameters
    :param stepsize: step size for aggregation
    :param metric: similarity
    :param dp: magnitude of randomization
    :return: updated server model parameters
    """
    w_next = copy.deepcopy(w_server)
    att, att_mat = {}, {}
    for k in w_server.keys():
        if isinstance(w_server[k], torch.LongTensor):
            w_next[k] = w_server[k]
        else:
            w_next[k] = torch.zeros_like(w_server[k]).cpu()

        att[k] = torch.zeros(len(w_clients)).cpu()

    for k in w_next.keys():
        if isinstance(w_server[k], torch.LongTensor):
            continue

        for i in range(0, len(w_clients)):
            # L2 norm
            att[k][i] = torch.norm(w_server[k]-w_clients[i][k], p=metric)

    for k in w_next.keys():
        att[k] = F.softmax(att[k], dim=0)

    for k in w_next.keys():
        if isinstance(w_server[k], torch.LongTensor):
            continue

        if 'running_var' in k:
            w_next[k] = w_server[k]
            continue

        att_weight = torch.zeros_like(w_server[k])
        for i in range(0, len(w_clients)):
            att_weight += torch.mul(w_server[k]-w_clients[i][k], att[k][i])

        w_next[k] = w_server[k] - torch.mul(att_weight, stepsize) + torch.mul(torch.randn(w_server[k].shape), dp)

    return w_next

def aggregate_att_with_other_coeffs(w_clients, w_server, stepsize, metric, dp, client_metrics, server_metric):
    """
    Attentive aggregation
    :param w_clients: list of client model parameters
    :param w_server: server model parameters
    :param stepsize: step size for aggregation
    :param metric: similarity
    :param dp: magnitude of randomization
    :return: updated server model parameters
    """
    w_next = copy.deepcopy(w_server)
    
    #
    att_other = {}
    for _key in server_metric.keys():
        att_other[_key] = torch.zeros(len(w_clients)).cpu()
        
    for _key in server_metric.keys():
        for _c in range(len(w_clients)):
            att_other[_key][_c] = torch.abs(client_metrics[_key][_c] - server_metric[_key])
    
    att, att_mat = {}, {}
    for k in w_server.keys():
        if isinstance(w_server[k], torch.LongTensor):
            w_next[k] = w_server[k]
        else:
            w_next[k] = torch.zeros_like(w_server[k]).cpu()

        att[k] = torch.zeros(len(w_clients)).cpu()

    for k in w_next.keys():
        if isinstance(w_server[k], torch.LongTensor):
            continue

        for i in range(0, len(w_clients)):
            # L2 norm
            att[k][i] = torch.norm(w_server[k]-w_clients[i][k], p=metric)

    for k in w_next.keys():
        att[k] = F.softmax(att[k], dim=0)

    for k in w_next.keys():
        if isinstance(w_server[k], torch.LongTensor):
            continue

        if 'running_var' in k:
            w_next[k] = w_server[k]
            continue

        att_weight = torch.zeros_like(w_server[k])
        for i in range(0, len(w_clients)):
            att_weight += torch.mul(w_server[k]-w_clients[i][k], att[k][i])

        w_next[k] = w_server[k] - torch.mul(att_weight, stepsize) + torch.mul(torch.randn(w_server[k].shape), dp)

    return w_next


def aggregate_att_selected(w_clients, w_server, stepsize, metric, dp, keyword):

    w_next = copy.deepcopy(w_server)
    att = {}
    for k in w_server.keys():
        if isinstance(w_server[k], torch.LongTensor):
            w_next[k] = w_server[k]
        else:
            if keyword in k:
                w_next[k] = torch.zeros_like(w_server[k]).cpu()

        att[k] = torch.zeros(len(w_clients)).cpu()

    for k in w_next.keys():
        if isinstance(w_server[k], torch.LongTensor):
            continue

        if keyword in k:
            for i in range(0, len(w_clients)):
                # print(f'{k}:{svd_vector_weight(w_server[k], w_clients[i][k])}')
                # att[k][i] = svd_vector_weight(w_server[k], w_clients[i][k])
                att[k][i] = torch.norm(w_server[k]-w_clients[i][k], p=metric)

    for k in w_next.keys():
        if keyword in k:
            att[k] = F.softmax(att[k], dim=0)

    for k in w_next.keys():
        if isinstance(w_server[k], torch.LongTensor):
            continue

        if 'running_var' in k:
            w_next[k] = w_server[k]
            continue
        if keyword in k:
            att_weight = torch.zeros_like(w_server[k])
            for i in range(0, len(w_clients)):
                att_weight += torch.mul(w_server[k]-w_clients[i][k], att[k][i])

            w_next[k] = w_server[k] - torch.mul(att_weight, stepsize) + torch.mul(torch.randn(w_server[k].shape), dp)

    return w_next


def svd_vector_weight(server, client):
    assert 1 == client.shape[-1] and 1 == client.shape[-2]
    assert 1 == server.shape[-1] and 1 == server.shape[-2]

    U_c, S_c, Vh_c = np.linalg.svd(client[:, :, 0, 0])
    U_s, S_s, Vh_s = np.linalg.svd(server[:, :, 0, 0])

    U_dis = 0
    Vh_dis = 0

    for _ind in range(server[:, :, 0, 0].shape[0]):
        U_dis += cosine(U_s[_ind, :], U_c[_ind, :])

    for _ind in range(server[:, :, 0, 0].shape[1]):
        Vh_dis += cosine(Vh_s[_ind, :], Vh_c[_ind, :])

    S_dis = np.sum(S_c - S_s)

    return (U_dis + Vh_dis + S_dis)


def aggregate_svd_avg(w, server, dp):
    """

    Args:
        w:
        server:
        dp:

    Returns:

    """
    w_avg = copy.deepcopy(server)

    for k in w_avg.keys():
        if 'gcn.conv.weight' in k:
            _U, _S, _Vh = np.linalg.svd(server[k][:, :, 0, 0].cpu().numpy())
            _U_avg = np.zeros_like(_U)
            _S_avg = np.zeros_like(_S)
            _Vh_avg = np.zeros_like(_Vh)

            _U_avg += _U
            _S_avg += _S
            _Vh_avg += _Vh

            for i in range(len(w)):
                _temp_U, _temp_S, _temp_Vh = np.linalg.svd(w[i][k][:, :, 0, 0].cpu().numpy())
                _U_avg += _temp_U
                _S_avg += _temp_S
                _Vh_avg += _temp_Vh

            _U_avg = np.divide(_U_avg, len(w))
            _S_avg = np.divide(_S_avg, len(w))
            _Vh_avg = np.divide(_Vh_avg, len(w))

            _smat = np.zeros((w_avg[k][:, :, 0, 0].shape[0], w_avg[k][:, :, 0, 0].shape[1]))
            _smat[:w_avg[k][:, :, 0, 0].shape[1], :w_avg[k][:, :, 0, 0].shape[1]] = np.diag(_S)

            w_avg[k][:, :, 0, 0] = torch.from_numpy(np.dot(_U, np.dot(_smat, _Vh)))

    return w_avg


def aggregate_att_svd(w, server, step_size, dp):
    """
    Federated averaging
    :param w: list of client model parameters
    :param dp: magnitude of randomization
    :return: updated server model parameters
    """
    w_avg = copy.deepcopy(server)

    # att_U, att_S, att_Vh = {}, {}, {}
    # for k in server.keys():
    #     att_U[k] = np.zeros(len(w))
    #     att_S[k] = np.zeros(len(w))
    #     att_Vh[k] = np.zeros(len(w))
    #
    # for k in w_avg.keys():
    #     if 'gcn.conv.weight' in k:
    #         _U, _S, _Vh = np.linalg.svd(server[k][:, :, 0, 0].cpu().numpy())
    #         for i in range(len(w)):
    #             _temp_U, _temp_S, _temp_Vh = np.linalg.svd(w[i][k][:, :, 0, 0].cpu().numpy())
    #             _U_wei = np.linalg.norm(_temp_U - _U, 2)
    #             _S_wei = np.linalg.norm(_temp_S - _S, 2)
    #             _Vh_wei = np.linalg.norm(_temp_Vh - _Vh, 2)
    #             att_U[k][i] = _U_wei
    #             att_S[k][i] = _S_wei
    #             att_Vh[k][i] = _Vh_wei
    #
    # for k in w_avg.keys():
    #     if 'gcn.conv.weight' in k:
    #         att_U[k] = softmax(att_U[k], axis=0)
    #         att_S[k] = softmax(att_U[k], axis=0)
    #         att_Vh[k] = softmax(att_U[k], axis=0)

    # Attention is created.
    for k in w_avg.keys():
        if 'gcn.conv.weight' in k:
            _U, _S, _Vh = np.linalg.svd(server[k][:, :, 0, 0].cpu().numpy())
            _U_att = np.zeros((_U.shape[0], len(w)))
            _S_att = np.zeros((_S.shape[0], len(w)))
            _Vh_att = np.zeros((_Vh.shape[0], len(w)))
            for i in range(len(w)):
                _temp_U, _temp_S, _temp_Vh = np.linalg.svd(w[i][k][:, :, 0, 0].cpu().numpy())

                _temp_U_diff = _U - _temp_U
                _temp_S_diff = _S - _temp_S
                _temp_Vh_diff = _Vh - _temp_Vh

                for _ind in range(_U.shape[0]):
                    _U_att[_ind, i] = np.linalg.norm(_temp_U_diff[_ind, :], 2)
                for _ind in range(_S.shape[0]):
                    _S_att[_ind, i] = np.abs(_temp_S_diff[_ind])
                for _ind in range(_Vh.shape[0]):
                    _Vh_att[_ind, i] = np.linalg.norm(_temp_Vh_diff[_ind, :], 2)

            for _ind in range(_U.shape[0]):
                _U_att[_ind, :] = np.divide(_U_att[_ind, :], np.sum(_U_att[_ind, :]))
            for _ind in range(_S.shape[0]):
                _S_att[_ind, :] = np.divide(_S_att[_ind, :], np.sum(_S_att[_ind, :]))
            for _ind in range(_Vh.shape[0]):
                _Vh_att[_ind, :] = np.divide(_Vh_att[_ind, :], np.sum(_Vh_att[_ind, :]))


            for i in range(len(w)):
                _temp_U, _temp_S, _temp_Vh = np.linalg.svd(w[i][k][:, :, 0, 0].cpu().numpy())
                for _ind in range(_U.shape[0]):
                    _U[_ind, :] += (_U[_ind, :] - _temp_U[_ind, :]) * _U_att[_ind, i] * step_size
                for _ind in range(_S.shape[0]):
                    _S[_ind] += (_S[_ind] - _temp_S[_ind]) * _S_att[_ind, i] * step_size
                for _ind in range(_Vh.shape[0]):
                    _Vh[_ind, :] += (_Vh[_ind, :] - _temp_Vh[_ind, :]) * _Vh_att[_ind, i] * step_size

            _smat = np.zeros((w_avg[k][:, :, 0, 0].shape[0], w_avg[k][:, :, 0, 0].shape[1]))
            _smat[:w_avg[k][:, :, 0, 0].shape[1], :w_avg[k][:, :, 0, 0].shape[1]] = np.diag(_S)
            w_avg[k][:, :, 0, 0] = torch.from_numpy(np.dot(_U, np.dot(_smat, _Vh)))

    return w_avg


# def aggregate_att_svd(w, server, step_size, dp):
#     """
#     Federated averaging
#     :param w: list of client model parameters
#     :param dp: magnitude of randomization
#     :return: updated server model parameters
#     """
#     w_avg = copy.deepcopy(server)
#
#     att_U, att_S, att_Vh = {}, {}, {}
#     for k in server.keys():
#         att_U[k] = np.zeros(len(w))
#         att_S[k] = np.zeros(len(w))
#         att_Vh[k] = np.zeros(len(w))
#
#     for k in w_avg.keys():
#         if 'gcn.conv.weight' in k:
#             _U, _S, _Vh = np.linalg.svd(server[k][:, :, 0, 0].cpu().numpy())
#             for i in range(len(w)):
#                 _temp_U, _temp_S, _temp_Vh = np.linalg.svd(w[i][k][:, :, 0, 0].cpu().numpy())
#                 _U_wei = np.linalg.norm(_temp_U - _U, 2)
#                 _S_wei = np.linalg.norm(_temp_S - _S, 2)
#                 _Vh_wei = np.linalg.norm(_temp_Vh - _Vh, 2)
#                 att_U[k][i] = _U_wei
#                 att_S[k][i] = _S_wei
#                 att_Vh[k][i] = _Vh_wei
#
#     for k in w_avg.keys():
#         if 'gcn.conv.weight' in k:
#             att_U[k] = softmax(att_U[k], axis=0)
#             att_S[k] = softmax(att_U[k], axis=0)
#             att_Vh[k] = softmax(att_U[k], axis=0)
#
#     # Attention is created.
#     for k in w_avg.keys():
#         if 'gcn.conv.weight' in k:
#             _U, _S, _Vh = np.linalg.svd(server[k][:, :, 0, 0].cpu().numpy())
#             _U_avg = np.zeros_like(_U)
#             _S_avg = np.zeros_like(_S)
#             _Vh_avg = np.zeros_like(_Vh)
#             for i in range(len(w)):
#                 _temp_U, _temp_S, _temp_Vh = np.linalg.svd(w[i][k][:, :, 0, 0].cpu().numpy())
#                 _U_avg += np.multiply(att_U[k][i], (_U - _temp_U))
#                 _S_avg += np.multiply(att_S[k][i], (_S - _temp_S))
#                 _Vh_avg += np.multiply(att_Vh[k][i], (_Vh - _temp_Vh))
#             _U = _U - np.multiply(_U_avg, step_size)
#             _S = _S - np.multiply(_S_avg, step_size)
#             _Vh = _Vh - np.multiply(_Vh_avg, step_size)
#
#             _smat = np.zeros((w_avg[k][:, :, 0, 0].shape[0], w_avg[k][:, :, 0, 0].shape[1]))
#             _smat[:w_avg[k][:, :, 0, 0].shape[1], :w_avg[k][:, :, 0, 0].shape[1]] = np.diag(_S)
#             w_avg[k][:, :, 0, 0] = torch.from_numpy(np.dot(_U, np.dot(_smat, _Vh)))
#
#     return w_avg


def average_weights(w, dp):
    """
    Federated averaging
    :param w: list of client model parameters
    :param dp: magnitude of randomization
    :return: updated server model parameters
    """
    w_avg = copy.deepcopy(w[0])
    for k in w_avg.keys():
        if 'gcn.conv.weight' in k:
            for i in range(1, len(w)):
                w_avg[k] = w_avg[k] + w[i][k]
            w_avg[k] = torch.div(w_avg[k], len(w)) + torch.mul(torch.randn(w_avg[k].shape), dp)
    return w_avg


def fuse_test():
    pt_files = [
        './trained_models/1-2mins-9-10mins-8-9-mins_drop_1.0_29.pt',
        './trained_models/smoothed_trajectories-0400-0415_deli_downsampled_by_4_2-3mins_no_overlap_distance_545_selected_clients__49.pt',
        './trained_models/smoothed_trajectories-0400-0415_deli_downsampled_by_4_4-5mins_no_overlap_distance_545_selected_clients_drop_1.0_49.pt',
        './trained_models/smoothed_trajectories-0400-0415_deli_downsampled_by_4_0-1mins_no_overlap_distance_545_selected_clients__49.pt',
        './trained_models/smoothed_trajectories-0400-0415_deli_downsampled_by_4_6-7mins_no_overlap_distance_545_selected_clients_49_drop_0.2_worst.pt'
    ]

    clients = []
    for _p in pt_files:
        clients.append(torch.load(_p, map_location=torch.device('cpu'))['xin_graph_seq2seq_model'])

    graph_args = {'max_hop': 2, 'num_node': 200}
    global_model = GRIPModel(in_channels=6, graph_args=graph_args, edge_importance_weighting=False)

    global_st = torch.load('./trained_models/smoothed_trajectories-0400-0415_deli_downsampled_by_4_5-6mins_no_overlap_distance_545_selected_clients__49.pt',
                           map_location=torch.device('cpu'))['xin_graph_seq2seq_model']
    global_model.to(dev)

    val_paths = [
        './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_10-11mins_no_overlap_distance_545.pkl',
        './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_11-12mins_no_overlap_distance_545.pkl',
        './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_12-13mins_no_overlap_distance_545.pkl',
        './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_13-14mins_no_overlap_distance_545.pkl',
        './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_14-15mins_no_overlap_distance_545.pkl'
    ]


    print(f' *** Start Fusing *** ')
    print(f'Validating global model ...')
    global_model.load_state_dict(global_st)
    run_val_select_clients(global_model, val_paths, '', 0, 0, graph_args)

    for _e in range(1):
        # print(f'Starting epoch {_e}')
        # global_st = aggregate_att(clients, global_st, 0.001, 2, 0)
        # global_st = aggregate_att_selected(clients, global_st, 0.005, 2, 0, 'gcn')
        global_st = average_weights(clients, 0)
        # global_st = aggregate_svd_avg(clients, global_st, 0)
        # global_st = aggregate_att_svd(clients, global_st, 0.0001, 0)
        # if _e % 10 == 0:
        print(f'Validating on Fused model ...')
        global_model.load_state_dict(global_st)
        run_val_select_clients(global_model, val_paths, '', 0, 0, graph_args)


def get_data_from_log(log_path: str, config: dict):
    assert os.path.exists(log_path)

    with open(log_path, 'r') as reader:
        contents = reader.readlines()

    loss = []
    for _line_ind, _line in enumerate(contents):

        if config['LOSS_KEY_WORD'] in _line:
            _data = _line.split(':')[-1].strip()
            _data = [float(d) for d in _data.split()]
            for _ind in range(len(_data) -1):
                loss.append((f'loss_{_ind}', _data[_ind]))
            loss.append(('loss_sum', _data[-1]))

    loss_df = pd.DataFrame(data=loss, columns=['loss_name', 'loss_val'])

    return loss_df

def get_val_data_from_log(log_path: str, config: dict):
    pass

def get_plot(data: pd.DataFrame, config: dict):

    fig = px.line(data, color='loss_name', markers=True)
    fig.show()

def get_log_config():
    config = {}
    config['LOSS_KEY_WORD'] = 'Val_Epoch'
    config['VAL_SPLITTER'] = '- Val -'
    config['TRAIN_SPLITTER'] = '- Train -'
    return config

def fuse_train():
    graph_args = {'max_hop': 2, 'num_node': 200}
    client_data_path = [
        './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_0-1mins_no_overlap.pkl',
        './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_1-2mins_no_overlap.pkl',
        './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_2-3mins_no_overlap.pkl',
        './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_3-4mins_no_overlap.pkl',
        './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_4-5mins_no_overlap.pkl',
        './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_5-6mins_no_overlap.pkl',
        './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_6-7mins_no_overlap.pkl',
        './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_7-8mins_no_overlap.pkl',
        './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_8-9mins_no_overlap.pkl',
        './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_9-10mins_no_overlap.pkl',
        './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_10-11mins_no_overlap.pkl',
        './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_11-12mins_no_overlap.pkl',
        './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_12-13mins_no_overlap.pkl',
        './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_13-14mins_no_overlap.pkl',
        './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_14-15mins_no_overlap.pkl'
    ]
    client_loaders_train = []
    client_loaders_val = []
    client_optimizers = []
    client_models = []
    clients = 4
    for _c in range(clients):
        client_loaders_train.append(
            data_loader(client_data_path[0], graph_args, pra_batch_size=batch_size_train, pra_shuffle=True,
                        pra_drop_last=True, train_val_test='train')
        )
        client_loaders_val.append(
            data_loader(client_data_path[0], graph_args, pra_batch_size=batch_size_train, pra_shuffle=False,
                        pra_drop_last=False, train_val_test='val')
        )
        model = GRIPModel(in_channels=6, graph_args=graph_args, edge_importance_weighting=False)
        model.to(dev)
        client_optimizers.append(
            optim.Adam([{'params': model.parameters()}, ], )
        )
        client_models.append(
            model
        )



if __name__ == '__main__':
    graph_args = {'max_hop': 2, 'num_node': 200}
    model = GRIPModel(in_channels=6, graph_args=graph_args, edge_importance_weighting=False)
    # model = GRIPModel_with_replaced_graph_param_return_graph(in_channels=6, graph_args=graph_args, edge_importance_weighting=True)
    model.to(dev)

    # fresh_model = GRIPModel_with_replaced_graph_param_return_graph(in_channels=6, graph_args=graph_args, edge_importance_weighting=True)
    # fresh_model.to(dev)

    # pkl_drop_ratio = [1, 0.9, 0.75, 0.7, 0.55, 0.5, 0.4, 0.35, 0.2, 0.2]
    pkl_drop_ratio = [1.0]
    pkl_files = [
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_1-2mins_no_overlap_distance_545.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_9-10mins_no_overlap_distance_545.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_2-3mins_no_overlap_distance_545.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_6-7mins_no_overlap_distance_545.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_5-6mins_no_overlap_distance_545.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_8-9mins_no_overlap_distance_545.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_3-4mins_no_overlap_distance_545.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_7-8mins_no_overlap_distance_545.pkl',
        './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_4-5mins_no_overlap_distance_545_timestamp_uid.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_0-1mins_no_overlap_distance_545.pkl'

        #[
        #    './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_1-2mins_no_overlap_distance_545.pkl',
        #    './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_9-10mins_no_overlap_distance_545.pkl',
        #    './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_8-9mins_no_overlap_distance_545.pkl',
        #    './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_2-3mins_no_overlap_distance_545.pkl',
        #    './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_4-5mins_no_overlap_distance_545.pkl',
        #    './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_0-1mins_no_overlap_distance_545.pkl',
        #    './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_6-7mins_no_overlap_distance_545.pkl'
        #]
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_0-1mins_no_overlap_noised_local_x_local_y_3_variance_3_distance_545.pkl'
    ]

    val_pkl_files = [
            './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_10-11mins_no_overlap_distance_545.pkl',
            './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_11-12mins_no_overlap_distance_545.pkl',
            './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_12-13mins_no_overlap_distance_545.pkl',
            './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_13-14mins_no_overlap_distance_545.pkl',
            './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_14-15mins_no_overlap_distance_545.pkl'
        ]

    # pkl_files = [
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_0-1mins_no_overlap_distance_545.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_1-2mins_no_overlap_distance_545.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_2-3mins_no_overlap_distance_545.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_3-4mins_no_overlap_distance_545.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_4-5mins_no_overlap_distance_545.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_5-6mins_no_overlap_distance_545.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_6-7mins_no_overlap_distance_545.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_7-8mins_no_overlap_distance_545.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_8-9mins_no_overlap_distance_545.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_9-10mins_no_overlap_distance_545.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_10-11mins_no_overlap_distance_545.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_11-12mins_no_overlap_distance_545.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_12-13mins_no_overlap_distance_545.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_13-14mins_no_overlap_distance_545.pkl',
        # './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_14-15mins_no_overlap_distance_545.pkl'
        # ]

    # pkl_files = [
    #     './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_0-1mins_no_overlap.pkl',
    #     './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_5-6mins_no_overlap.pkl',
    #     './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_7-8mins_no_overlap.pkl',
    #     './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_10-11mins_no_overlap.pkl',
    # ]

    # pkl_files = [
    #     './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_0-10mins_no_overlap_distance_545.pkl'
    # ]

    pt_files = [
        './trained_models/1-2mins-9-10mins-8-9-mins_drop_1.0_29.pt'
        # 'trained_models/smoothed_trajectories-0400-0415_deli_downsampled_by_4_4-5mins_no_overlap_distance_545_selected_clients_drop_0.4_49.pt',
        # 'trained_models/smoothed_trajectories-0400-0415_deli_downsampled_by_4_4-5mins_no_overlap_distance_545_selected_clients_drop_1.0_49.pt'

        # './trained_models/smoothed_trajectories-0400-0415_deli_downsampled_by_4_2-3mins_no_overlap_distance_545_selected_clients__49_best.pt',
        # './trained_models/smoothed_trajectories-0400-0415_deli_downsampled_by_4_1-2mins_no_overlap_distance_545_selected_clients__49.pt',
        # './trained_models/smoothed_trajectories-0400-0415_deli_downsampled_by_4_9-10mins_no_overlap_distance_545_selected_clients__49.pt',
        # './trained_models/smoothed_trajectories-0400-0415_deli_downsampled_by_4_6-7mins_no_overlap_distance_545_selected_clients__49_drop_0.7.pt',
        # './trained_models/smoothed_trajectories-0400-0415_deli_downsampled_by_4_5-6mins_no_overlap_distance_545_selected_clients__49.pt',
        # './trained_models/smoothed_trajectories-0400-0415_deli_downsampled_by_4_8-9mins_no_overlap_distance_545_selected_clients__49.pt',
        # './trained_models/smoothed_trajectories-0400-0415_deli_downsampled_by_4_3-4mins_no_overlap_distance_545_selected_clients__49.pt',
        # './trained_models/smoothed_trajectories-0400-0415_deli_downsampled_by_4_7-8mins_no_overlap_distance_545_selected_clients__49.pt',
        # './trained_models/smoothed_trajectories-0400-0415_deli_downsampled_by_4_4-5mins_no_overlap_distance_545_selected_clients__49.pt',
        # './trained_models/smoothed_trajectories-0400-0415_deli_downsampled_by_4_0-1mins_no_overlap_distance_545_selected_clients__49.pt',
        # './trained_models/smoothed_trajectories-0400-0415_deli_downsampled_by_4_6-7mins_no_overlap_distance_545_selected_clients_49_drop_0.2_worst.pt',
    ]

    # train and evaluate model
    for _pkl_ind, pkl in enumerate(pkl_files):
        print(f'Starting to train on {pkl} ...')
        # run_trainval_replace_params_two_model(model, None, None, pkl, None, graph_args)

        # run_trainval(model, pkl, '', graph_args)

        run_trainval_select_clients(model, pkl, val_pkl_files, pkl_drop_ratio[_pkl_ind], graph_args)

        # model.load_state_dict(torch.load(pkl)['xin_graph_seq2seq_model'])

        # run_val_select_clients(model, val_pkl_files, '', 0, 0, graph_args)

        # run_val_select_clients(model, './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_10-11mins_no_overlap_distance_545.pkl', '', 0, 0, graph_args)
        # run_val_select_clients(model, './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_11-12mins_no_overlap_distance_545.pkl', '', 0, 0, graph_args)
        # run_val_select_clients(model, './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_12-13mins_no_overlap_distance_545.pkl', '', 0, 0, graph_args)
        # run_val_select_clients(model, './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_13-14mins_no_overlap_distance_545.pkl', '', 0, 0, graph_args)
        # run_val_select_clients(model, './training_data/smoothed_trajectories-0400-0415_deli_downsampled_by_4_14-15mins_no_overlap_distance_545.pkl', '', 0, 0, graph_args)

        # run_explain(model, pkl, graph_args=graph_args)


        # renamed = 'log_selected_clients_' + os.path.basename(pkl).split('.')[0] + '.txt'
        renamed = 'log_selected_clients_0-1_nosied_drop_1.0.log'
        os.rename('./trained_models/log.txt', f'./training_log/{renamed}')


# if __name__ == '__main__':
#     logger.add('aggregation_log.log')
#     fuse_test()







